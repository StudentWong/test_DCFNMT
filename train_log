nohup: ignoring input
Namespace(batch_size=32, epochs=50, input_sz=125, lr=0.005, padding=1.0, print_freq=30, range=10, resume='', save='./work', start_epoch=0, weight_decay=1e-06, workers=8)
GPU NUM:  1
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
/home/lilium/anaconda3/envs/caijihuzhuo/lib/python3.7/site-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.
  warnings.warn(warning.format(ret))
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Epoch: [0][0/119]	Time 2.045 (2.045)	Data 1.244 (1.244)	Loss 1596.7076 (1596.7076)	
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2048.0
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1024.0
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 512.0
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 256.0
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 128.0
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 64.0
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32.0
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16.0
Epoch: [0][30/119]	Time 0.709 (0.753)	Data 0.000 (0.041)	Loss 1327.3793 (1474.1882)	
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.0
Epoch: [0][60/119]	Time 0.709 (0.732)	Data 0.000 (0.021)	Loss 1357.7065 (1432.6729)	
Epoch: [0][90/119]	Time 0.709 (0.724)	Data 0.000 (0.014)	Loss 1085.9891 (1382.3725)	
Test: [0/29]	Time 2.509 (2.509)	Loss 734.5439 (734.5439)	
 * Loss 749.4296 (745.5004)
/home/lilium/anaconda3/envs/caijihuzhuo/lib/python3.7/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
Epoch: [1][0/119]	Time 2.075 (2.075)	Data 1.349 (1.349)	Loss 1012.9081 (1012.9081)	
Epoch: [1][30/119]	Time 0.709 (0.754)	Data 0.000 (0.044)	Loss 1135.9633 (1020.8749)	
Epoch: [1][60/119]	Time 0.715 (0.733)	Data 0.000 (0.022)	Loss 938.3925 (997.0522)	
Epoch: [1][90/119]	Time 0.706 (0.724)	Data 0.000 (0.015)	Loss 926.7041 (981.3026)	
Test: [0/29]	Time 1.296 (1.296)	Loss 664.2758 (664.2758)	
 * Loss 669.9586 (672.8848)
Epoch: [2][0/119]	Time 1.822 (1.822)	Data 1.090 (1.090)	Loss 937.9816 (937.9816)	
Epoch: [2][30/119]	Time 0.706 (0.743)	Data 0.000 (0.036)	Loss 939.0726 (934.8490)	
Epoch: [2][60/119]	Time 0.707 (0.725)	Data 0.000 (0.018)	Loss 924.7603 (939.1725)	
Epoch: [2][90/119]	Time 0.707 (0.719)	Data 0.000 (0.012)	Loss 994.6425 (972.3977)	
Test: [0/29]	Time 1.347 (1.347)	Loss 659.0517 (659.0517)	
 * Loss 660.1846 (655.4875)
Epoch: [3][0/119]	Time 1.765 (1.765)	Data 1.026 (1.026)	Loss 912.3810 (912.3810)	
Epoch: [3][30/119]	Time 0.707 (0.741)	Data 0.000 (0.033)	Loss 1085.2610 (928.8458)	
Epoch: [3][60/119]	Time 0.707 (0.724)	Data 0.000 (0.017)	Loss 898.3004 (942.5289)	
Epoch: [3][90/119]	Time 0.706 (0.718)	Data 0.000 (0.011)	Loss 1060.6857 (935.1150)	
Test: [0/29]	Time 1.516 (1.516)	Loss 708.5155 (708.5155)	
 * Loss 715.3186 (713.3547)
Epoch: [4][0/119]	Time 1.807 (1.807)	Data 1.082 (1.082)	Loss 927.9370 (927.9370)	
Epoch: [4][30/119]	Time 0.706 (0.742)	Data 0.000 (0.035)	Loss 924.5353 (924.8084)	
Epoch: [4][60/119]	Time 0.706 (0.724)	Data 0.000 (0.018)	Loss 907.7965 (920.8582)	
Epoch: [4][90/119]	Time 0.707 (0.718)	Data 0.000 (0.012)	Loss 907.3050 (919.4788)	
Test: [0/29]	Time 2.012 (2.012)	Loss 633.9226 (633.9226)	
 * Loss 635.7193 (636.8703)
Epoch: [5][0/119]	Time 1.745 (1.745)	Data 1.003 (1.003)	Loss 915.2993 (915.2993)	
Epoch: [5][30/119]	Time 0.706 (0.740)	Data 0.000 (0.032)	Loss 913.0026 (917.7188)	
Epoch: [5][60/119]	Time 0.706 (0.724)	Data 0.000 (0.017)	Loss 1018.6821 (920.4473)	
Epoch: [5][90/119]	Time 0.706 (0.718)	Data 0.000 (0.011)	Loss 948.2246 (954.6089)	
Test: [0/29]	Time 1.506 (1.506)	Loss 665.1605 (665.1605)	
 * Loss 666.0439 (665.3091)
Epoch: [6][0/119]	Time 1.963 (1.963)	Data 1.244 (1.244)	Loss 912.7797 (912.7797)	
Epoch: [6][30/119]	Time 0.706 (0.747)	Data 0.000 (0.040)	Loss 909.4755 (909.0082)	
Epoch: [6][60/119]	Time 0.707 (0.727)	Data 0.000 (0.020)	Loss 903.3875 (908.3630)	
Epoch: [6][90/119]	Time 0.707 (0.720)	Data 0.000 (0.014)	Loss 921.6225 (911.4410)	
Test: [0/29]	Time 1.724 (1.724)	Loss 672.4297 (672.4297)	
 * Loss 679.0974 (675.9448)
Epoch: [7][0/119]	Time 1.746 (1.746)	Data 0.996 (0.996)	Loss 893.3901 (893.3901)	
Epoch: [7][30/119]	Time 0.706 (0.740)	Data 0.000 (0.032)	Loss 916.2604 (928.2965)	
Epoch: [7][60/119]	Time 0.706 (0.724)	Data 0.000 (0.016)	Loss 914.4393 (916.0760)	
Epoch: [7][90/119]	Time 0.706 (0.718)	Data 0.000 (0.011)	Loss 890.3521 (910.5569)	
Test: [0/29]	Time 1.408 (1.408)	Loss 648.0598 (648.0598)	
 * Loss 649.0317 (652.3692)
Epoch: [8][0/119]	Time 1.558 (1.558)	Data 0.816 (0.816)	Loss 866.4385 (866.4385)	
Epoch: [8][30/119]	Time 0.706 (0.734)	Data 0.000 (0.026)	Loss 946.2078 (909.6054)	
Epoch: [8][60/119]	Time 0.706 (0.720)	Data 0.000 (0.013)	Loss 867.8358 (917.4737)	
Epoch: [8][90/119]	Time 0.706 (0.716)	Data 0.000 (0.009)	Loss 899.3260 (917.0065)	
Test: [0/29]	Time 1.282 (1.282)	Loss 757.8842 (757.8842)	
 * Loss 784.1767 (769.8829)
Epoch: [9][0/119]	Time 1.797 (1.797)	Data 1.071 (1.071)	Loss 942.3520 (942.3520)	
Epoch: [9][30/119]	Time 0.706 (0.742)	Data 0.000 (0.035)	Loss 904.1811 (910.8683)	
Epoch: [9][60/119]	Time 0.706 (0.724)	Data 0.000 (0.018)	Loss 879.6507 (897.3488)	
Epoch: [9][90/119]	Time 0.706 (0.718)	Data 0.000 (0.012)	Loss 900.8554 (891.6156)	
Test: [0/29]	Time 1.615 (1.615)	Loss 704.6556 (704.6556)	
 * Loss 718.9960 (715.9120)
Epoch: [10][0/119]	Time 2.027 (2.027)	Data 1.306 (1.306)	Loss 862.7544 (862.7544)	
Epoch: [10][30/119]	Time 0.706 (0.749)	Data 0.000 (0.042)	Loss 881.7109 (872.7521)	
Epoch: [10][60/119]	Time 0.706 (0.728)	Data 0.000 (0.021)	Loss 885.0639 (876.5018)	
Epoch: [10][90/119]	Time 0.706 (0.721)	Data 0.000 (0.014)	Loss 869.1627 (876.1920)	
Test: [0/29]	Time 1.592 (1.592)	Loss 715.7610 (715.7610)	
 * Loss 731.6908 (726.1072)
Epoch: [11][0/119]	Time 1.907 (1.907)	Data 1.168 (1.168)	Loss 866.0031 (866.0031)	
Epoch: [11][30/119]	Time 0.706 (0.745)	Data 0.000 (0.038)	Loss 888.0851 (886.3223)	
Epoch: [11][60/119]	Time 0.706 (0.726)	Data 0.000 (0.019)	Loss 846.0617 (877.2349)	
Epoch: [11][90/119]	Time 0.706 (0.720)	Data 0.000 (0.013)	Loss 916.6753 (873.5753)	
Test: [0/29]	Time 1.609 (1.609)	Loss 718.3380 (718.3380)	
 * Loss 745.0505 (733.3494)
Epoch: [12][0/119]	Time 1.645 (1.645)	Data 0.900 (0.900)	Loss 835.3911 (835.3911)	
Epoch: [12][30/119]	Time 0.707 (0.737)	Data 0.000 (0.029)	Loss 949.5807 (906.4847)	
Epoch: [12][60/119]	Time 0.706 (0.722)	Data 0.000 (0.015)	Loss 859.3253 (910.2524)	
Epoch: [12][90/119]	Time 0.707 (0.717)	Data 0.000 (0.010)	Loss 864.4896 (893.1845)	
Test: [0/29]	Time 1.566 (1.566)	Loss 704.4638 (704.4638)	
 * Loss 718.6149 (714.6386)
Epoch: [13][0/119]	Time 1.523 (1.523)	Data 0.802 (0.802)	Loss 825.5065 (825.5065)	
Epoch: [13][30/119]	Time 0.707 (0.734)	Data 0.000 (0.026)	Loss 863.7239 (848.1349)	
Epoch: [13][60/119]	Time 0.706 (0.720)	Data 0.000 (0.013)	Loss 875.8873 (851.1682)	
Epoch: [13][90/119]	Time 0.707 (0.716)	Data 0.000 (0.009)	Loss 831.9699 (852.8489)	
Test: [0/29]	Time 1.289 (1.289)	Loss 775.3586 (775.3586)	
 * Loss 780.8978 (776.5725)
Epoch: [14][0/119]	Time 1.785 (1.785)	Data 1.044 (1.044)	Loss 869.2007 (869.2007)	
Epoch: [14][30/119]	Time 0.707 (0.741)	Data 0.000 (0.034)	Loss 846.8687 (860.5645)	
Epoch: [14][60/119]	Time 0.706 (0.724)	Data 0.000 (0.017)	Loss 807.1691 (853.3839)	
Epoch: [14][90/119]	Time 0.706 (0.718)	Data 0.000 (0.012)	Loss 841.3227 (849.6052)	
Test: [0/29]	Time 1.577 (1.577)	Loss 740.6450 (740.6450)	
 * Loss 758.7015 (755.5836)
Epoch: [15][0/119]	Time 1.770 (1.770)	Data 0.997 (0.997)	Loss 857.8804 (857.8804)	
Epoch: [15][30/119]	Time 0.707 (0.742)	Data 0.000 (0.032)	Loss 862.3878 (879.0691)	
Epoch: [15][60/119]	Time 0.706 (0.724)	Data 0.000 (0.016)	Loss 827.9324 (865.0234)	
Epoch: [15][90/119]	Time 0.706 (0.718)	Data 0.000 (0.011)	Loss 844.6530 (862.0472)	
Test: [0/29]	Time 1.651 (1.651)	Loss 694.5558 (694.5558)	
 * Loss 709.1584 (701.7940)
Epoch: [16][0/119]	Time 1.711 (1.711)	Data 0.984 (0.984)	Loss 837.4638 (837.4638)	
Epoch: [16][30/119]	Time 0.707 (0.739)	Data 0.000 (0.032)	Loss 864.3016 (841.9002)	
Epoch: [16][60/119]	Time 0.706 (0.723)	Data 0.000 (0.016)	Loss 827.9971 (839.7606)	
Epoch: [16][90/119]	Time 0.706 (0.717)	Data 0.000 (0.011)	Loss 862.4723 (838.1936)	
Test: [0/29]	Time 2.022 (2.022)	Loss 778.9067 (778.9067)	
 * Loss 811.1836 (795.6304)
Epoch: [17][0/119]	Time 2.102 (2.102)	Data 1.389 (1.389)	Loss 849.6235 (849.6235)	
Epoch: [17][30/119]	Time 0.706 (0.751)	Data 0.000 (0.045)	Loss 876.3037 (861.6267)	
Epoch: [17][60/119]	Time 0.706 (0.729)	Data 0.000 (0.023)	Loss 830.4936 (859.1296)	
Epoch: [17][90/119]	Time 0.706 (0.722)	Data 0.000 (0.015)	Loss 844.2754 (852.4676)	
Test: [0/29]	Time 1.970 (1.970)	Loss 740.8569 (740.8569)	
 * Loss 751.7285 (758.7902)
Epoch: [18][0/119]	Time 1.637 (1.637)	Data 0.889 (0.889)	Loss 810.6794 (810.6794)	
Epoch: [18][30/119]	Time 0.707 (0.737)	Data 0.000 (0.029)	Loss 843.4594 (835.0204)	
Epoch: [18][60/119]	Time 0.707 (0.722)	Data 0.000 (0.015)	Loss 824.9421 (835.0669)	
Epoch: [18][90/119]	Time 0.706 (0.717)	Data 0.000 (0.010)	Loss 849.1691 (832.8976)	
Test: [0/29]	Time 1.696 (1.696)	Loss 750.4917 (750.4917)	
 * Loss 761.5800 (758.7526)
Epoch: [19][0/119]	Time 1.717 (1.717)	Data 0.980 (0.980)	Loss 822.4664 (822.4664)	
Epoch: [19][30/119]	Time 0.706 (0.739)	Data 0.000 (0.032)	Loss 854.0018 (828.7315)	
Epoch: [19][60/119]	Time 0.706 (0.723)	Data 0.000 (0.016)	Loss 832.0125 (845.9170)	
Epoch: [19][90/119]	Time 0.706 (0.718)	Data 0.000 (0.011)	Loss 827.3260 (841.8839)	
Test: [0/29]	Time 1.433 (1.433)	Loss 774.3469 (774.3469)	
 * Loss 806.6296 (793.4548)
Epoch: [20][0/119]	Time 1.586 (1.586)	Data 0.860 (0.860)	Loss 809.1434 (809.1434)	
Epoch: [20][30/119]	Time 0.707 (0.735)	Data 0.000 (0.028)	Loss 814.6616 (823.5465)	
Epoch: [20][60/119]	Time 0.706 (0.721)	Data 0.000 (0.014)	Loss 819.0594 (822.7751)	
Epoch: [20][90/119]	Time 0.706 (0.716)	Data 0.000 (0.010)	Loss 838.7833 (822.2886)	
Test: [0/29]	Time 1.287 (1.287)	Loss 791.3609 (791.3609)	
 * Loss 812.1673 (808.0280)
Epoch: [21][0/119]	Time 1.558 (1.558)	Data 0.820 (0.820)	Loss 851.7064 (851.7064)	
Epoch: [21][30/119]	Time 0.707 (0.734)	Data 0.000 (0.027)	Loss 837.3457 (828.7652)	
Epoch: [21][60/119]	Time 0.707 (0.721)	Data 0.000 (0.014)	Loss 842.8146 (841.0672)	
Epoch: [21][90/119]	Time 0.708 (0.716)	Data 0.000 (0.009)	Loss 866.6717 (851.9187)	
Test: [0/29]	Time 1.698 (1.698)	Loss 757.7191 (757.7191)	
 * Loss 772.4250 (768.3516)
Epoch: [22][0/119]	Time 1.871 (1.871)	Data 1.126 (1.126)	Loss 823.7443 (823.7443)	
Epoch: [22][30/119]	Time 0.706 (0.744)	Data 0.000 (0.036)	Loss 871.7543 (840.5729)	
Epoch: [22][60/119]	Time 0.707 (0.726)	Data 0.000 (0.019)	Loss 829.1539 (839.3722)	
Epoch: [22][90/119]	Time 0.707 (0.719)	Data 0.000 (0.012)	Loss 794.6944 (832.3494)	
Test: [0/29]	Time 1.323 (1.323)	Loss 716.6511 (716.6511)	
 * Loss 737.4226 (735.8930)
Epoch: [23][0/119]	Time 2.168 (2.168)	Data 1.448 (1.448)	Loss 805.1061 (805.1061)	
Epoch: [23][30/119]	Time 0.706 (0.754)	Data 0.000 (0.047)	Loss 819.3537 (815.1369)	
Epoch: [23][60/119]	Time 0.706 (0.730)	Data 0.000 (0.024)	Loss 805.7540 (812.6542)	
Epoch: [23][90/119]	Time 0.706 (0.722)	Data 0.000 (0.016)	Loss 833.5063 (815.1046)	
Test: [0/29]	Time 1.383 (1.383)	Loss 728.6765 (728.6765)	
 * Loss 767.8925 (759.5407)
Epoch: [24][0/119]	Time 1.581 (1.581)	Data 0.826 (0.826)	Loss 789.7772 (789.7772)	
Epoch: [24][30/119]	Time 0.706 (0.737)	Data 0.000 (0.028)	Loss 827.0720 (813.6336)	
Epoch: [24][60/119]	Time 0.706 (0.722)	Data 0.000 (0.014)	Loss 817.2570 (820.1535)	
Epoch: [24][90/119]	Time 0.706 (0.717)	Data 0.000 (0.010)	Loss 858.7744 (825.9091)	
Test: [0/29]	Time 2.126 (2.126)	Loss 764.7575 (764.7575)	
 * Loss 763.2079 (776.4705)
Epoch: [25][0/119]	Time 1.757 (1.757)	Data 1.002 (1.002)	Loss 789.9386 (789.9386)	
Epoch: [25][30/119]	Time 0.707 (0.740)	Data 0.000 (0.032)	Loss 835.0136 (830.6708)	
Epoch: [25][60/119]	Time 0.706 (0.724)	Data 0.000 (0.017)	Loss 800.3322 (828.7271)	
Epoch: [25][90/119]	Time 0.707 (0.718)	Data 0.000 (0.011)	Loss 826.0485 (822.7611)	
Test: [0/29]	Time 1.902 (1.902)	Loss 788.9307 (788.9307)	
 * Loss 791.8746 (798.7418)
Epoch: [26][0/119]	Time 1.719 (1.719)	Data 0.998 (0.998)	Loss 793.9440 (793.9440)	
Epoch: [26][30/119]	Time 0.706 (0.740)	Data 0.000 (0.032)	Loss 820.8340 (818.3384)	
Epoch: [26][60/119]	Time 0.707 (0.723)	Data 0.000 (0.016)	Loss 785.5327 (814.3757)	
Epoch: [26][90/119]	Time 0.706 (0.718)	Data 0.000 (0.011)	Loss 892.5805 (816.7689)	
Test: [0/29]	Time 2.035 (2.035)	Loss 762.6511 (762.6511)	
 * Loss 782.8683 (795.8395)
Epoch: [27][0/119]	Time 1.507 (1.507)	Data 0.781 (0.781)	Loss 807.7274 (807.7274)	
Epoch: [27][30/119]	Time 0.707 (0.734)	Data 0.000 (0.026)	Loss 811.4177 (811.3819)	
Epoch: [27][60/119]	Time 0.706 (0.721)	Data 0.000 (0.013)	Loss 788.0464 (811.1161)	
Epoch: [27][90/119]	Time 0.706 (0.716)	Data 0.000 (0.009)	Loss 802.9999 (808.3586)	
Test: [0/29]	Time 1.609 (1.609)	Loss 782.3535 (782.3535)	
 * Loss 817.4662 (814.0049)
Epoch: [28][0/119]	Time 1.719 (1.719)	Data 0.985 (0.985)	Loss 798.5965 (798.5965)	
Epoch: [28][30/119]	Time 0.706 (0.739)	Data 0.000 (0.032)	Loss 811.8476 (805.9974)	
Epoch: [28][60/119]	Time 0.707 (0.723)	Data 0.000 (0.016)	Loss 817.7858 (809.4535)	
Epoch: [28][90/119]	Time 0.706 (0.718)	Data 0.000 (0.011)	Loss 844.1874 (815.7313)	
Test: [0/29]	Time 1.289 (1.289)	Loss 771.7799 (771.7799)	
 * Loss 799.4444 (794.4828)
Epoch: [29][0/119]	Time 1.726 (1.726)	Data 0.994 (0.994)	Loss 801.1103 (801.1103)	
Epoch: [29][30/119]	Time 0.706 (0.739)	Data 0.000 (0.032)	Loss 860.2939 (823.6638)	
Epoch: [29][60/119]	Time 0.706 (0.723)	Data 0.000 (0.016)	Loss 797.3657 (822.0890)	
Epoch: [29][90/119]	Time 0.706 (0.718)	Data 0.000 (0.011)	Loss 810.9518 (820.0141)	
Test: [0/29]	Time 1.495 (1.495)	Loss 777.9829 (777.9829)	
 * Loss 814.2679 (809.3602)
Epoch: [30][0/119]	Time 1.549 (1.549)	Data 0.799 (0.799)	Loss 812.8802 (812.8802)	
Epoch: [30][30/119]	Time 0.706 (0.734)	Data 0.000 (0.026)	Loss 830.3919 (814.6733)	
Epoch: [30][60/119]	Time 0.707 (0.720)	Data 0.000 (0.013)	Loss 779.6443 (814.1022)	
Epoch: [30][90/119]	Time 0.706 (0.716)	Data 0.000 (0.009)	Loss 876.8640 (826.2516)	
Test: [0/29]	Time 1.527 (1.527)	Loss 740.9336 (740.9336)	
 * Loss 750.6074 (755.6667)
Epoch: [31][0/119]	Time 1.660 (1.660)	Data 0.899 (0.899)	Loss 810.1168 (810.1168)	
Epoch: [31][30/119]	Time 0.706 (0.739)	Data 0.000 (0.030)	Loss 835.2635 (817.5989)	
Epoch: [31][60/119]	Time 0.706 (0.723)	Data 0.000 (0.016)	Loss 808.1784 (811.2961)	
Epoch: [31][90/119]	Time 0.708 (0.717)	Data 0.000 (0.010)	Loss 842.7432 (810.1654)	
Test: [0/29]	Time 1.268 (1.268)	Loss 771.1260 (771.1260)	
 * Loss 787.9800 (789.5668)
Epoch: [32][0/119]	Time 1.538 (1.538)	Data 0.806 (0.806)	Loss 811.2562 (811.2562)	
Epoch: [32][30/119]	Time 0.708 (0.735)	Data 0.000 (0.028)	Loss 808.9177 (809.0250)	
Epoch: [32][60/119]	Time 0.706 (0.721)	Data 0.000 (0.014)	Loss 803.1992 (804.0517)	
Epoch: [32][90/119]	Time 0.706 (0.716)	Data 0.000 (0.010)	Loss 830.1465 (805.2554)	
Test: [0/29]	Time 1.638 (1.638)	Loss 809.2922 (809.2922)	
 * Loss 827.2426 (825.2156)
Epoch: [33][0/119]	Time 1.636 (1.636)	Data 0.897 (0.897)	Loss 823.7167 (823.7167)	
Epoch: [33][30/119]	Time 0.706 (0.737)	Data 0.000 (0.029)	Loss 798.6013 (807.2871)	
Epoch: [33][60/119]	Time 0.706 (0.722)	Data 0.000 (0.015)	Loss 796.0677 (797.4187)	
Epoch: [33][90/119]	Time 0.706 (0.717)	Data 0.000 (0.010)	Loss 812.8657 (797.0090)	
Test: [0/29]	Time 1.601 (1.601)	Loss 788.4442 (788.4442)	
 * Loss 807.7484 (803.4085)
Epoch: [34][0/119]	Time 1.569 (1.569)	Data 0.824 (0.824)	Loss 793.9268 (793.9268)	
Epoch: [34][30/119]	Time 0.706 (0.735)	Data 0.000 (0.027)	Loss 808.7402 (796.7181)	
Epoch: [34][60/119]	Time 0.707 (0.721)	Data 0.000 (0.014)	Loss 795.4819 (798.5546)	
Epoch: [34][90/119]	Time 0.707 (0.716)	Data 0.000 (0.009)	Loss 801.8578 (801.5027)	
Test: [0/29]	Time 1.581 (1.581)	Loss 811.5950 (811.5950)	
 * Loss 839.0313 (833.8325)
Epoch: [35][0/119]	Time 1.526 (1.526)	Data 0.797 (0.797)	Loss 789.0048 (789.0048)	
Epoch: [35][30/119]	Time 0.707 (0.733)	Data 0.000 (0.026)	Loss 839.2236 (797.1286)	
Epoch: [35][60/119]	Time 0.706 (0.720)	Data 0.000 (0.013)	Loss 808.3043 (796.3768)	
Epoch: [35][90/119]	Time 0.706 (0.715)	Data 0.000 (0.009)	Loss 810.4965 (799.5542)	
Test: [0/29]	Time 1.284 (1.284)	Loss 766.2725 (766.2725)	
 * Loss 786.2604 (786.6599)
Epoch: [36][0/119]	Time 1.816 (1.816)	Data 1.085 (1.085)	Loss 801.5962 (801.5962)	
Epoch: [36][30/119]	Time 0.707 (0.742)	Data 0.000 (0.035)	Loss 802.0287 (798.8005)	
Epoch: [36][60/119]	Time 0.706 (0.725)	Data 0.000 (0.018)	Loss 828.8661 (800.2993)	
Epoch: [36][90/119]	Time 0.707 (0.719)	Data 0.000 (0.012)	Loss 809.0380 (806.3112)	
Test: [0/29]	Time 1.420 (1.420)	Loss 834.6862 (834.6862)	
 * Loss 842.3032 (845.5564)
Epoch: [37][0/119]	Time 1.650 (1.650)	Data 0.913 (0.913)	Loss 806.7612 (806.7612)	
Epoch: [37][30/119]	Time 0.706 (0.737)	Data 0.000 (0.030)	Loss 798.8854 (801.7706)	
Epoch: [37][60/119]	Time 0.706 (0.722)	Data 0.000 (0.015)	Loss 802.2086 (803.5752)	
Epoch: [37][90/119]	Time 0.706 (0.717)	Data 0.000 (0.010)	Loss 821.5299 (803.1223)	
Test: [0/29]	Time 1.328 (1.328)	Loss 879.2719 (879.2719)	
 * Loss 888.9990 (890.2491)
Epoch: [38][0/119]	Time 2.050 (2.050)	Data 1.337 (1.337)	Loss 811.2025 (811.2025)	
Epoch: [38][30/119]	Time 0.708 (0.750)	Data 0.000 (0.043)	Loss 781.9431 (804.9878)	
Epoch: [38][60/119]	Time 0.706 (0.729)	Data 0.000 (0.022)	Loss 796.9767 (801.5472)	
Epoch: [38][90/119]	Time 0.708 (0.721)	Data 0.000 (0.015)	Loss 800.0861 (798.8404)	
Test: [0/29]	Time 1.930 (1.930)	Loss 848.8157 (848.8157)	
 * Loss 865.5170 (868.0902)
Epoch: [39][0/119]	Time 1.578 (1.578)	Data 0.829 (0.829)	Loss 811.5591 (811.5591)	
Epoch: [39][30/119]	Time 0.706 (0.735)	Data 0.000 (0.027)	Loss 816.2058 (809.4533)	
Epoch: [39][60/119]	Time 0.707 (0.721)	Data 0.000 (0.014)	Loss 759.5087 (797.8056)	
Epoch: [39][90/119]	Time 0.707 (0.716)	Data 0.000 (0.009)	Loss 780.8386 (797.5090)	
Test: [0/29]	Time 1.312 (1.312)	Loss 875.2639 (875.2639)	
 * Loss 891.1615 (889.7139)
Epoch: [40][0/119]	Time 1.533 (1.533)	Data 0.802 (0.802)	Loss 771.5098 (771.5098)	
Epoch: [40][30/119]	Time 0.707 (0.740)	Data 0.000 (0.033)	Loss 792.7167 (787.7987)	
Epoch: [40][60/119]	Time 0.707 (0.724)	Data 0.000 (0.017)	Loss 785.0756 (789.2709)	
Epoch: [40][90/119]	Time 0.706 (0.718)	Data 0.000 (0.011)	Loss 783.3181 (789.0649)	
Test: [0/29]	Time 1.366 (1.366)	Loss 880.5028 (880.5028)	
 * Loss 909.0406 (898.7456)
Epoch: [41][0/119]	Time 1.537 (1.537)	Data 0.829 (0.829)	Loss 765.1470 (765.1470)	
Epoch: [41][30/119]	Time 0.706 (0.734)	Data 0.000 (0.028)	Loss 794.5557 (793.5612)	
Epoch: [41][60/119]	Time 0.707 (0.721)	Data 0.000 (0.014)	Loss 769.7504 (794.4457)	
Epoch: [41][90/119]	Time 0.707 (0.716)	Data 0.000 (0.009)	Loss 811.0417 (796.5639)	
Test: [0/29]	Time 1.685 (1.685)	Loss 814.3493 (814.3493)	
 * Loss 825.7403 (825.3161)
Epoch: [42][0/119]	Time 1.910 (1.910)	Data 1.181 (1.181)	Loss 783.2474 (783.2474)	
Epoch: [42][30/119]	Time 0.707 (0.746)	Data 0.000 (0.038)	Loss 808.8628 (784.7396)	
Epoch: [42][60/119]	Time 0.706 (0.726)	Data 0.000 (0.019)	Loss 792.0182 (789.0680)	
Epoch: [42][90/119]	Time 0.707 (0.720)	Data 0.000 (0.013)	Loss 780.2873 (788.3964)	
Test: [0/29]	Time 1.402 (1.402)	Loss 864.3402 (864.3402)	
 * Loss 887.1584 (877.2101)
Epoch: [43][0/119]	Time 1.706 (1.706)	Data 0.981 (0.981)	Loss 795.0483 (795.0483)	
Epoch: [43][30/119]	Time 0.707 (0.739)	Data 0.000 (0.032)	Loss 787.8491 (794.3765)	
Epoch: [43][60/119]	Time 0.706 (0.723)	Data 0.000 (0.016)	Loss 754.3751 (792.1694)	
Epoch: [43][90/119]	Time 0.706 (0.717)	Data 0.000 (0.011)	Loss 786.8135 (789.7807)	
Test: [0/29]	Time 1.709 (1.709)	Loss 882.4099 (882.4099)	
 * Loss 895.5385 (889.1638)
Epoch: [44][0/119]	Time 1.877 (1.877)	Data 1.121 (1.121)	Loss 796.1564 (796.1564)	
Epoch: [44][30/119]	Time 0.707 (0.745)	Data 0.000 (0.036)	Loss 796.8434 (796.8387)	
Epoch: [44][60/119]	Time 0.706 (0.726)	Data 0.000 (0.018)	Loss 784.1370 (791.9160)	
Epoch: [44][90/119]	Time 0.706 (0.719)	Data 0.000 (0.012)	Loss 794.0820 (786.3725)	
Test: [0/29]	Time 1.529 (1.529)	Loss 864.9464 (864.9464)	
 * Loss 875.8256 (873.8229)
Epoch: [45][0/119]	Time 2.068 (2.068)	Data 1.344 (1.344)	Loss 777.2971 (777.2971)	
Epoch: [45][30/119]	Time 0.706 (0.750)	Data 0.000 (0.043)	Loss 778.0291 (781.7044)	
Epoch: [45][60/119]	Time 0.706 (0.729)	Data 0.000 (0.022)	Loss 770.1637 (779.3620)	
Epoch: [45][90/119]	Time 0.706 (0.721)	Data 0.000 (0.015)	Loss 777.5268 (778.3621)	
Test: [0/29]	Time 1.405 (1.405)	Loss 904.8525 (904.8525)	
 * Loss 931.4031 (924.4111)
Epoch: [46][0/119]	Time 2.157 (2.157)	Data 1.439 (1.439)	Loss 792.0046 (792.0046)	
Epoch: [46][30/119]	Time 0.706 (0.753)	Data 0.000 (0.046)	Loss 820.1503 (787.5969)	
Epoch: [46][60/119]	Time 0.706 (0.730)	Data 0.000 (0.024)	Loss 791.2875 (789.7699)	
Epoch: [46][90/119]	Time 0.708 (0.722)	Data 0.000 (0.016)	Loss 777.2006 (786.6769)	
Test: [0/29]	Time 1.573 (1.573)	Loss 849.3167 (849.3167)	
 * Loss 881.5176 (876.4479)
Epoch: [47][0/119]	Time 1.749 (1.749)	Data 1.042 (1.042)	Loss 775.9224 (775.9224)	
Epoch: [47][30/119]	Time 0.706 (0.741)	Data 0.000 (0.034)	Loss 797.3337 (786.6103)	
Epoch: [47][60/119]	Time 0.706 (0.724)	Data 0.000 (0.017)	Loss 758.1326 (779.4512)	
Epoch: [47][90/119]	Time 0.707 (0.718)	Data 0.000 (0.012)	Loss 817.9772 (779.4192)	
Test: [0/29]	Time 1.978 (1.978)	Loss 858.3135 (858.3135)	
 * Loss 875.0175 (872.6778)
Epoch: [48][0/119]	Time 2.168 (2.168)	Data 1.451 (1.451)	Loss 775.9960 (775.9960)	
Epoch: [48][30/119]	Time 0.707 (0.754)	Data 0.000 (0.047)	Loss 771.4749 (774.0959)	
Epoch: [48][60/119]	Time 0.706 (0.730)	Data 0.000 (0.024)	Loss 769.9653 (776.0066)	
Epoch: [48][90/119]	Time 0.706 (0.722)	Data 0.000 (0.016)	Loss 784.7336 (778.4096)	
Test: [0/29]	Time 1.786 (1.786)	Loss 845.3314 (845.3314)	
 * Loss 867.1110 (864.9036)
Epoch: [49][0/119]	Time 1.616 (1.616)	Data 0.886 (0.886)	Loss 758.1683 (758.1683)	
Epoch: [49][30/119]	Time 0.706 (0.737)	Data 0.000 (0.029)	Loss 779.3576 (766.3956)	
Epoch: [49][60/119]	Time 0.706 (0.722)	Data 0.000 (0.015)	Loss 743.3388 (767.3778)	
Epoch: [49][90/119]	Time 0.707 (0.717)	Data 0.000 (0.010)	Loss 759.4880 (769.5204)	
Test: [0/29]	Time 1.385 (1.385)	Loss 847.7197 (847.7197)	
 * Loss 866.3094 (864.8847)
